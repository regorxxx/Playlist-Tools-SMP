Creates intelligent "spotify-like" playlists using high-level data from 
tracks similar to the currently selected one according to genre, style,
key, etc.

When their score is over 'scoreFilter', then they are included in the 
final pool.

After all tracks have been evaluated and the final pool is complete, 
some of them are chosen to populate the playlist. You can choose whether
this final selection is done according to score, randomly chosen, etc.

All settings are configurable on the properties panel and/ or menus.

These are the weight/tags pairs checked by default:
+-----------------+-------------++----------------+---------------+
|      Weight     |     Tag     ||     Weight     |      Tag      |
+-----------------+-------------++----------------+---------------+
+-----------------+-------------++----------------+---------------+
| genreWeight     | genre       || styleWeight    | style         |
+-----------------+-------------++----------------+---------------+
| dyngenreWeight  |(virtual tag)|| moodWeight     | mood          |
+-----------------+-------------++----------------+---------------+
| keyWeight       | key         || dateWeight     | $year(%date%) |
+-----------------+-------------++----------------+---------------+
| bpmWeight       | bpm         || composerWeight | composer      |
+-----------------+-------------++----------------+---------------+

There are 2 custom tags which can be set by the user too:
+-----------------+-----------++-----------------+-----------+
|      Weight     |    Tag    ||      Weight     |    Tag    |
+-----------------+-----------++-----------------+-----------+
+-----------------+-----------++-----------------+-----------+
|                 | (empty by ||                 | (empty by |
| customStrWeight |  default) || customNumWeight |  default) |
+-----------------+-----------++-----------------+-----------+
	
Any Weight/tags pair can be remapped and/or merged (sep. by comma). 
For example, linking genreWeight to 2 different genre tags on your files:
+-------+-----------------------------+
|  Tag  | Remap                       |
+-------+-----------------------------+
+-------+-----------------------------+
| genre | allmusic_genre,my_genre_tag |
+-------+-----------------------------+
	
Some weight/tags pairs can be linked to TitleFormat Expr. Use tag names 
instead of TF expressions when possible (+ performance). 
For example, see 'date': TF is used to have the same results for 
tracks with YYYY-MM tags or YYYY tags.
+-----------+--------------------+
|    Tag    | Remap              |
+-----------+--------------------+
+-----------+--------------------+
| date      | $year(%date%)      |
+-----------+--------------------+
| customNum | (empty by default) |
+-----------+--------------------+
	
Genre and Style tags (or their remapped values) can be globally 
filtered. See 'genreStyleFilter'. Case sensitive. For example, when
comparing genre values from track A to track B, 'Soundtrack' and 
'Radio Program' values are omitted:
+------------------+--------------------------+
| Filter           | Values                   |
+------------------+--------------------------+
+------------------+--------------------------+
| genreStyleFilter | Soundtrack,Radio Program |
+------------------+--------------------------+
	
There are 3 methods to calc similarity: WEIGHT, GRAPH and DYNGENRE.
+----------+--------------------------+---------------------------------+
| Name     | Method                   | Weights                         |
+----------+--------------------------+---------------------------------+
+----------+--------------------------+---------------------------------+
|          |                          | Uses genreWeight, styleWeight,  |
|          |                          |      moodWeight, keyWeight,     |
|          |                          |      dateWeight, dateRange,     |
|          |                          |      bpmWeight, bpmRange,       |
|          |                          |      composerWeight,            |
|          |                          |      customStrWeight,           |
| WEIGHT   | Score filter             |      customNumWeight            |
+----------+--------------------------+---------------------------------+
|          |                          | Same than WEIGHT                |
| GRAPH    | Score + Distance filters |      + max_graph_distance       |
+----------+--------------------------+---------------------------------+
|          |                          | Same than WEIGHT                |
| DYNGENRE | Score filter             |      + dyngenreWeight           |
+----------+--------------------------+---------------------------------+

+----------+-----------------------------------------------------------+
| Name     | Description                                               |
+----------+-----------------------------------------------------------+
+----------+-----------------------------------------------------------+
|          | Calculates similarity by score via tags comparison.       |
|          |                                                           |
|          | Similarity is calculated by simple string matching        |
|          |      ('Rock' != 'Soul') and ranges for numeric tags.      |
|          |      This means some coherence in tags is needed to       |
|          |      make it work, and the script only works with         |
|          |      high level data (tags) which should have been        |
|          |      added to files previously using manual or            |
|          |      automatic methods (like MusicBrainz Picard,          |
| WEIGHT   |      see note at bottom).                                 |
+----------+-----------------------------------------------------------+
|          | Apart from scoring, it compares the genre/styles tags     |
|          |      set to the ones of the reference track using a       |
|          |      graph and calculating their min. mean distance.      |
|          |                                                           |
|          | For ex. for reference track with genre/styles (A,B,D),    |
|          |      minimum mean distance is done considering (A,B,D)    |
|          |      set against all library tracks. Lets consider a      |
|          |      track with (A,B,C) genre/styles. First set matches   |
|          |      at 2 points (0 distance), therefore only one path    |
|          |      must be found, i.e. the shortest path from (A,B,D)   |
|          |      to (C) which will be x. Then the mean distance       |
|          |      is calculated dividing the sum by the number of      |
|          |      points of the reference track: (0 + 0 + x)/3         |
|          |                                                           |
|          | Imagine Google maps for genre/styles, and looking for     |
|          |      the distance from Rock to Jazz for ex.               |
|          |      'max_graph_distance' sets the max distance allowed,  |
|          |      so every track with genre/styles farther than that   |
|          |      value will not be included in the final pool. Note   |
|          |      this is totally different to simple string matching, |
|          |      'Acid Rock' may be similar to 'Psychedelic Rock'     |
|          |      even if they are totally different tag values        |
|          |      (strings).                                           |
|          |                                                           |
|          | This method is pretty computational intensive, we are     |
|          |      drawing a map with all known genres/styles and       |
|          |      calculating the shortest path between the            |
|          |      reference track and all the tracks from the          |
|          |      library (after some basic filtering). Somewhere      |
|          |      between 2 and 5 secs for 40 K tracks.                |
|          |                                                           |
|          | For a complete description of how it works check:         |
|          |      'helpers/music_graph_descriptors_xxx.js'             |
|          |                                                           |
|          | And to see the map rendered in your browser like a map    |
| GRAPH    |      check: 'Draw Graph.html'                             |
+----------+-----------------------------------------------------------+
|          | Uses a simplification of the GRAPH method. Let's say we   |
|          |      assign a number to every "big" cluster of points     |
|          |      on the music graph, then we can simply put any       |
|          |      genre/style point into any of those clusters and     |
|          |      give them a value. So 'Rock' would be linked to 3,   |
|          |      the same than 'Roots Rock' or 'Rock & Roll'.         |
|          |                                                           |
|          | It's a more complex method than WEIGHT, but less than     |
|          |      GRAPH, which allows cross-linking between            |
|          |      different genres breaking from string matching.      |
|          |                                                           |
|          | For a complete description of how it works check:         |
| DYNGENRE |      'helpers/dyngenre_map_xxx.js'                        |
+----------+-----------------------------------------------------------+

Note about genre/styles:
------------------------
GRAPH method doesn't care whether "Rock" is a genre or a style but the 
scoring part does! Both values are considered points without any 
distinction.

Genre weight is related to genres, style weight is related to styles.... 
But there is a workaround, let's say you only use genre tags (and put 
all values together there). Then set style weight to zero. 
It will just check genre tags and the graph part will work the same anyway.

Note about GRAPH/DYNGENRE exclusions:
-------------------------------------
Apart from the global filter (which applies to genre/style string 
matching for scoring purpose), there is another filtering done when 
mapping genres/styles to the graph or their associated static values. 
See 'map_distance_exclusions' at 'helpers/music_graph_descriptors_xxx.js'.

It includes those genre/style tags which are not related to an specific 
musical genre. For ex. "Acoustic" which could be applied to any genre.
They are filtered because they have no representation on the graph, not 
being a real genre/style but a musical characteristic of any musical 
composition.

Therefore, they are useful for similarity scoring purposes but not for 
the graph. That's why we don't use the global filter for them.
This second filtering stage is not really needed, but it greatly 
speedups the calculations if you have tons of files with these tags! 
In other words, any tag not included in 
'helpers/music_graph_descriptors_xxx.js' as part of the graph will be 
omitted for distance calcs, but you save time if you add it manually 
to the exclusions (otherwise the entire graph will be visited trying 
to find a match).

Note about editing 'helpers/music_graph_descriptors_xxx.js' or user file:
-------------------------------------------------------------------------
Instead of editing the main file, you can add any edit to an user set 
file named 'helpers/music_graph_descriptors_xxx_user.js'. Check sample 
for more info.

It's irrelevant whether you add your changes to the original file or the 
user's one but note on future script updates the main file may be 
updated too. 

That means you will need to manually merge the changes from the update 
with your own ones, if you want them. That's the only "problem" editing 
the main one. Both the html and foobar scripts will use any setting on 
the user file (as if it were in the main file), so there is no other
difference. Anything at this doc which points to 
'helpers/music_graph_descriptors_xxx.js' applies the same to 
'helpers/music_graph_descriptors_xxx_user.js'.

Note about High Level data, tag coherence, automatic tagging and Picard:
------------------------------------------------------------------------
Network players and servers like Spotify, Itunes Genius, YouTube, etc. 
offer similar services to these scripts. Whenever you play a track 
within their players, similar tracks are offered on a regular basis. 
All the work is done on the servers, so it seems to be magic for the user.
There are some important caveats for this approach: 

It only works because the tracks have been previously analyzed ('tagged')
on their server. And all the data is closed source and network
dependent. i.e. you can always listen to Spotify and your great 
playlist, at least while you pay them, those tracks are not removed for 
your region and you have a constant Internet connection.

That music listening model has clear drawbacks, and while the purpose of 
this caveat is not talking about them, at least we have to note the 
closed source  nature of that analysis data. Spotify's data is not the 
same than Youtube's data... and for sure, you can not make use of that
data for your library in any way.

Ironically, being at a point where machine learning and other methods of 
analysis are ubiquitous, they are mostly relegated behind a pay-wall. 
And every time a company or a developer wants to create similar features, 
they must start from scratch and create their own data models.

An offline similar program which does the same would be [MusicIP]( 
https://spicefly.com/article.php?page=what-is-musicip). It appeared as 
a viable alternative to that model, offering both an Internet server and
a complete ability to analyze files offline as fall-back. Nowadays, the
company is gone, the software is obsolete (although usable!) and 
documentation is missing for advanced features. The main problems? 
It was meant as a standalone solution, so there is no easy way to connect
other programs to its local server to create playlists on demand. 
It can be done, but requires manually refreshing and maintaining 
the server database with new tag changes, data analysis, and translating 
ratings (from foobar for ex.) to the program. The other big problem is 
analysis time.

It may well take a minute per track when calculating all the data 
needed... and the data is also closed source (so it has no meaning 
outside the program). The reason it takes so much time is simple, 
the program was created when machine learning was not a reality. 
MusicIP may well have been ahead of its time.

Back to topic, both online and offline methods due to its closed source 
nature greatly difficult interoperability between different programs and 
use-cases.

These scripts offer a solution to both problems, relying only in offline 
data (your tags) and open source data (your tags again). But to make it 
work, the data (your tags) need relevant info. Since every user fills their 
tags without following an universal convention (most times leaving some 
tags unfilled), the only requirement for these scripts to work is tag coherence:

	- Tags must point to high-level data, so analysis (whether 
	computational or human) must be done previously. 'Acoustic' or 
	'Happy' moods are high level data, 'barkbands' with a list of
	values is low-level data (meant to be used to calculate 
	high-level ones). For more info: https://acousticbrainz.org/data
	- Tags not present are simply skipped. The script doesn't expect 
	any specific tag to work, except the obvious ones (can not use 
	GRAPH method without genre/style tags). This is done to not 
	enforce an specific set of tags, only the ones you need / use.
	- Tags are not hard-linked to an specific tag-name convention. 
	Genre may have as tag name 'genre', 'my_genre' or 'hjk'.
	- Basic filtering features to solve some corner cases (for 
	genre/styles).
	- Casing must be the same along all tags. i.e. 'Rock' always 
	spelled as 'Rock'. Yes, it could be omitted using .toLowerCase(),
	but is a design decision, since it forces users to check the casing
	of their entire set of tags (ensuring a bit more consistency in
	other fields).
	- Reproducibility all along the library set. And this is the main 
	point of tag coherence. 
	
About Reproducibility: If two users tag a track with different genres or 
moods, then the results will be totally different. But that's not a 
problem as long as every user applies its own 'logic' to their entire 
library. i.e. if you have half of your library tagged right and the 
other half with missing tags, some wrongly set and others 'as is' when
you got the files... then there is no coherence at all in your set of
tracks nor your tags. Some follow a convention and others follow another
convention. 

To help with that here are 2 advises: tag your tracks properly (I don't
care about specific use-cases to solve what ifs) and take a look at 
MusicBrainz Picard (that's the open source part): 
https://picard.musicbrainz.org/

Now, you DON'T need to change all your tags or your entire library. But 
Picard offers 3 tags using the high-level open source data of 
AcousticBrainz: mood, key and BPM. That means, you can use your manual set
tags along those automatically set Picard's tags to fulfill both: your tag 
convention and reproducibility along your entire library. Also you can 
manually fix or change later any mood with your preferred editor or 
player. Picard also offers plugins to fill other tags like genres, 
composers, etc. Filling only empty tags, or adding them to the existing
ones, replacing them, ... whatever you want.
 
There are probably other solutions like fetching data from AllMusic 
(moods), lastFm (genres), Discogs (composers), etc. Use whatever you 
want as long as tag coherence and reproducibility are ensured. 

What happens if you don't want to (re)tag your files with moods, bpm, 
key, splitting genres/styles, ...? Then you will miss that part, that's 
all. But it works.

What about a library properly tagged but using 'rock' instead of 'Rock' 
or 'African Folk' instead of 'Nubian Folk' (although that's a bit racist 
you know ;)? Then use substitutions at 
'helpers/music_graph_descriptors_xxx.js' (not touching your files) 
and/or use mass tagging utilities to replace values (touching them).
And what about having some tracks of my library properly tagged and not 
others? Then... garbage in, garbage out. Your mileage may vary.